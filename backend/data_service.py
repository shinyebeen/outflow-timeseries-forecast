import streamlit as st
import pandas as pd

from utils.data_processor import (cached_preprocess_data,
                                 cached_analyze_outliers,
                                 cached_delete_outliers,
                                 cached_get_acf_pacf,
                                 cached_check_stationarity,
                                 cached_get_fft,
                                 cached_decompose_timeseries)
@st.cache_data(ttl=3600)
def load_data(file_path):
    if file_path.name.endswith('.csv'):
        df = pd.read_csv(file_path)
    elif file_path.name.endswith('.xlsx'):
        df = pd.read_excel(file_path)

    # ë‚ ì§œ í˜•ì‹ ì»¬ëŸ¼ í™•ì¸ í›„ ì—ëŸ¬ ì²˜ë¦¬
    if 'logTime' not in df.columns:
        first_col = df.columns[0]
        df.rename(columns={first_col: 'logTime'}, inplace=True)
        
    if 'logTime' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['logTime']):
        df['logTime'] = pd.to_datetime(df['logTime'])
    st.session_state.df = df

    # ìƒˆ ë°ì´í„°ê°€ ì—…ë¡œë“œë˜ë©´ ê´€ë ¨ session state ì´ˆê¸°í™”
    st.session_state.target = None  # íƒ€ê²Ÿ ë³€ìˆ˜ ì´ˆê¸°í™”
    st.session_state.test_size = 0.2  # í…ŒìŠ¤íŠ¸ ì‚¬ì´ì¦ˆ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
    
    # # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
            # default_end_date = pd.Timestamp(df['logTime'].max())
            # default_start_date = default_end_date - timedelta(days=30)
    
            # st.sidebar.markdown("##### ðŸ“… ë¶„ì„ ê¸°ê°„ ì„ íƒ", help="ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”. (ìµœëŒ€ 30ì¼)")
            
            # date_col1, date_col2 = st.sidebar.columns(2)
            
            # with date_col1:
            #     start_date = pd.Timestamp(st.date_input(
            #         "ì‹œìž‘ ë‚ ì§œ",
            #         default_start_date
            #     ))
                
            # with date_col2:
                    
            #     end_date = pd.Timestamp(st.date_input(
            #         "ì¢…ë£Œ ë‚ ì§œ",
            #         min_value=start_date,
            #         max_value=default_end_date
            #     ))
            
            # # ì„ íƒëœ ë‚ ì§œ ë²”ìœ„ ì¼ìˆ˜ ê³„ì‚°
            # date_range_days = (end_date - start_date).days
            
            # # ê¸°ê°„ í‘œì‹œ ì •ë³´ ë° ì‹œê°í™”
            # progress_value = min(date_range_days / 30, 1.0)
            # st.sidebar.progress(progress_value)
            # st.sidebar.text(f"ì„ íƒëœ ê¸°ê°„: {date_range_days + 1}ì¼ / ìµœëŒ€ 30ì¼")
            
            # if date_range_days > 25:
            #     st.sidebar.warning("ë°ì´í„° ì–‘ì´ ë§Žì„ìˆ˜ë¡ ë¶„ì„ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    
        #     # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼
        #     if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        #         try:
        #             filtered_df = df.loc[(df['logTime'] >= start_date) & (df['logTime'] <= end_date)]
        #             if filtered_df is not None and not filtered_df.empty:
        #                 st.session_state.df = filtered_df
        #                 st.rerun()  # í™”ë©´ ê°±ì‹ 
        #         except Exception as e:
        #             st.sidebar.error(f"ë°ì´í„° í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def update_series():
    """
    ì‹œê³„ì—´ ë°ì´í„° ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    """

    if st.session_state.df is not None:
        st.session_state.series = cached_preprocess_data(
            st.session_state.df,
            st.session_state.target
        )

        # ì´ì „ ê²°ê³¼ì™€ í˜„ìž¬ ì„¤ì • ë¹„êµ 
        if st.session_state.model_trained is not None:
            if ('prev_target' in st.session_state and 
                st.session_state.prev_target != st.session_state.target):
                st.session_state.model_trained = False
                st.session_state.forecasts = {}
                st.session_state.metrics = {}

        st.session_state.prev_target = st.session_state.target

        st.session_state.start_date = st.session_state.df['logTime'].min()
        st.session_state.end_date = st.session_state.df['logTime'].max()

        # ì‹œê°„ë‹¹ ì¸¡ì • ë¹ˆë„
        hours_span = (st.session_state.end_date - st.session_state.start_date).total_seconds() / 3600
        st.session_state.records_per_hour = st.session_state.df.shape[0] / max(hours_span, 1) # ìµœì†Œ 1ì‹œê°„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°


def analyze_outliers():
    if st.session_state.series is not None:
        result = cached_analyze_outliers(st.session_state.series)
        st.session_state.outliers = result
        
        return result
    return None

def delete_outliers(mode):
    """
    ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ 
    """
    if st.session_state.series is not None:
        cleaned_series = cached_delete_outliers(st.session_state.series, mode)
        st.session_state.cleaned_series = cleaned_series 

        return cleaned_series 

    return None

def analyze_acf_pacf(nlags=40):
    """
    ACF/PACF ë¶„ì„ ìˆ˜í–‰
    
    Args:
        nlags: ìµœëŒ€ ì‹œì°¨ (ê¸°ë³¸ê°’: 40)
    
    Returns:
        tuple: (ACF ê°’, PACF ê°’) íŠœí”Œ
    """
    if st.session_state.series is not None:
        try:
            acf_values, pacf_values = cached_get_acf_pacf(st.session_state.series, nlags)
            st.session_state.acf_values = acf_values
            st.session_state.pacf_values = pacf_values
            return acf_values, pacf_values
        
        except Exception as e:
            st.error(f"ACF/PACF ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
    return None, None


def analyze_stationarity():
    """
    ì •ìƒì„± ê²€ì • ìˆ˜í–‰
    
    Returns:
        dict: ì •ìƒì„± ê²€ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if st.session_state.series is not None:
        try:
            stationarity_result = cached_check_stationarity(st.session_state.series)
            st.session_state.stationarity_result = stationarity_result
            return stationarity_result
        except Exception as e:
            st.error(f"ì •ìƒì„± ê²€ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    return None

def analyze_fft():
    """
    ê³ ì†í‘¸ë¦¬ì— ë³€í™˜ ìˆ˜í–‰
    
    Returns:

    """
    if st.session_state.series is not None:
        try:
            # FFT ìˆ˜í–‰
            fft_result = cached_get_fft(st.session_state.series)
            st.session_state.fft_result = fft_result
            return fft_result
        except Exception as e:
            st.error(f"ê³ ì†í‘¸ë¦¬ì—ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
        
        return None


def analyze_decomposition(period=None):
    """
    ì‹œê³„ì—´ ë¶„í•´ ë¶„ì„ ìˆ˜í–‰
    
    Args:
        period: ê³„ì ˆì„± ì£¼ê¸° (ê¸°ë³¸ê°’: None)
    
    Returns:
        dict: ë¶„í•´ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """

    if period is None:
        period = st.session_state.period

    if st.session_state.series is not None:       
        try:
            decomposition = cached_decompose_timeseries(st.session_state.series, period)
            st.session_state.decomposition = decomposition
            return decomposition
        
        except Exception as e:
            st.error(f"ì‹œê³„ì—´ ë¶„í•´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None    
        
    return None
